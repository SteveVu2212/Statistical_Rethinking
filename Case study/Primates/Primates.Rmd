---
title: "Primates"
output: github_document
---

# Instalation

```{r}
rm(list=ls())
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

```{r}
library(MASS)
library(rstan)
library(shape)
library(tidyr)
require(visdat)
library(ggplot2)
library(dagitty)
library(gtools)
library(ellipse)
library(tidyverse)
library(rethinking)
```

```{r}
options(mc.cores = parallel::detectCores())
rstan_options(auto_write = TRUE)
```

# Load data

```{r}
data("Primates301")
d <- Primates301
head(d)
```

```{r}
str(d)
```

```{r}
vis_dat(d)
```

# 1. Poisson regression

```{r}
d2 <- d[complete.cases(d$social_learning, d$brain, d$research_effort),]
dim(d2); dim(d)
```

```{r}
d2$logbrain <- log(d2$brain)
d2$logresearch <- log(d2$research_effort)
```

```{r}
dlist <- list(
  N = nrow(d2),
  S = d2$social_learning,
  B = d2$logbrain,
  R = d2$logresearch
)
```


## Initial statistical models

$$
S_{i} \sim Poisson(\lambda_{i})\\
log(\lambda_{i}) = \alpha + \beta_{b}*B_{i}\\
\alpha \sim \\
\beta_{b} \sim \\
$$

## Define priors

Weakly informative priors of alpha produces reasonable average values of social learning in compared with  flat prior of Normal(0,10). We're going to use the Normal(1,1) prior for alpha

```{r}
set.seed(1)
N <- 200
plot(NULL, xlim=c(0,10), ylim=c(0,1),xlab="Average social learning", ylab="Density")
dens(exp(rnorm(N,0,1)), col=col.alpha(rangi2, 1), add=TRUE)
dens(exp(rnorm(N,1,1)), col=col.alpha("blue", 1), add=TRUE)
dens(exp(rnorm(N,0,10)), col=col.alpha("black", 1), add=TRUE)
```


The Normal(0,0.5) prior of beta shows that most of prior predictions is below 4 and some increases exponentially


```{r}
set.seed(2)
N <- 200
a = rnorm(N,1,1)
b = rnorm(N,0,0.5)
B_seq = seq(from=min(d2$logbrain), to=max(d2$logbrain), length.out=30)
plot(NULL, xlim=c(min(B_seq),max(B_seq)), ylim=c(0,10), xlab="Log brain size", ylab="Average social learning")
for(i in 1:100){
  curve(exp(a[i] + b[i]*x), add=TRUE, col=col.alpha(rangi2,0.5))
}
```

## Updated statistical models

$$
S_{i} \sim Poisson(\lambda_{i})\\
log(\lambda_{i}) = \alpha + \beta_{b}*B_{i}\\
\alpha \sim Normal(1,1)\\
\beta_{b} \sim Normal(0,0.5)\\
$$

```{r}
code_m1.1 <- "
data{
  int N;
  vector<lower=0>[N] B;
  int S[N];
}
parameters{
  real a;
  real bB;
}
model{
  vector[N] lambda;
  bB ~ normal(0,0.5);
  a ~ normal(1,1);
  for(i in 1:N){
    lambda[i] = a + bB*B[i];
    lambda[i] = exp(lambda[i]);
  }
  S ~ poisson(lambda);
}
generated quantities{
  vector[N] log_lik;
  vector[N] lambda;
  for(i in 1:N){
    lambda[i] = a + bB*B[i];
    lambda[i] = exp(lambda[i]);
  }
  for(i in 1:N){
    log_lik[i] = poisson_lpmf(S[i] | lambda[i]);
  }
}
"
```


```{r}
m.1.1 <- stan(model_code=code_m1.1,data=dlist,chains=4,cores=4)
precis(m.1.1)
```


The estimates show a positive association of brain size with social learning. However, the sampling is unreliable with low efficient number of samples and high R_square.


## Posterior predictive checks

```{r}
set.seed(3)
post.1.1 <- extract.samples(m.1.1)
B_seq = seq(from=min(d2$logbrain), to=max(d2$logbrain), length.out=30)
mu <- matrix(0,nrow=length(post.1.1$a),ncol=30)
for(i in 1:30){mu[,i] = exp(post.1.1$a + post.1.1$bB*B_seq[i])}
# mu <- link(m.1.1, data=list(B=B_seq))
mu.mean <- apply(mu,2,mean)
mu.pi <- apply(mu,2,PI,prob=0.89)
```

```{r}
sim.social1.1 <- matrix(0,nrow=length(post.1.1$a),ncol=30)
for(i in 1:30){
  sim.social1.1[,i] = rpois(n=1e3, lambda=exp(post.1.1$a + post.1.1$bB*B_seq[i]))
}
# sim.social <- sim(m.1.1, data = list(B=B_seq))
sim.pi <- apply(sim.social1.1, 2, PI, prob=0.89)
```


```{r}
plot(NULL, xlim=c(min(d2$logbrain),max(d2$logbrain)), ylim=c(min(d2$social_learning),max(d2$social_learning)),
     ylab="Social Learning", xlab="Log brain size")
points(x=d2$logbrain, y=d2$social_learning, col=rangi2)
lines(x=B_seq,y=mu.mean, col=col.alpha("black",1))
shade(mu.pi, B_seq, col=col.alpha("blue",0.5))
shade(sim.pi, B_seq, col=col.alpha("gray",0.5))
```


There are two information extracted from the chart
* Many zero values of the outcome variable in the original data
* The posterior prediction is curved by outliers with extreme high values given a large brain size.

We need more information to conclude the impact of brain size on social learning due to the prevalence of zero values.


## Extended statistical models

$$
S_{i} \sim Poisson(\lambda_{i})\\
log(\lambda_{i}) = \alpha + \beta_{b}*B_{i} + \beta_{r}*R_{i}\\
\alpha \sim Normal(1,1)\\
\beta_{b} \sim Normal(0,0.5)\\
\beta_{r} \sim Normal(0,0.5)
$$
### Prior predictive checks

```{r}
set.seed(2)
N <- 200
a = rnorm(N,1,1)
b1 = rnorm(N,0,0.5)
b2 = rnorm(N,0,0.5)
B_seq = seq(from=min(d2$logbrain), to=max(d2$logbrain), length.out=30)
R_seq = seq(from=min(d2$logresearch), to=max(d2$logresearch), length.out=30)

prior.pred <- matrix(0,nrow=200,ncol=length(B_seq))
for(i in 1:length(B_seq)){
  prior.pred[,i] = exp(a + b1*B_seq[i] + b2*R_seq[i])
}

plot(NULL, xlim=c(min(B_seq),max(B_seq)), ylim=c(0,10), xlab="Log brain size", ylab="Average social learning")
for(i in 1:100){
  lines(x=B_seq,y=prior.pred[i,], add=TRUE, col=col.alpha(rangi2,0.5))
}
```

## Fit the model

```{r}
code_m1.2 <- "
data{
  int N;
  vector<lower=0>[N] B;
  vector<lower=0>[N] R;
  int S[N];
}
parameters{
  real a;
  real b1;
  real b2;
}
model{
  vector[N] lambda;
  b1 ~ normal(0,0.5);
  b2 ~ normal(0,0.5);
  a ~ normal(1,1);
  for(i in 1:N){
    lambda[i] = a + b1*B[i] + b2*R[i];
    lambda[i] = exp(lambda[i]);
  }
  S ~ poisson(lambda);
}
generated quantities{
  vector[N] log_lik;
  vector[N] lambda;
  for(i in 1:N){
    lambda[i] = a + b1*B[i] + b2*R[i];
    lambda[i] = exp(lambda[i]);
  }
  for(i in 1:N){
    log_lik[i] = poisson_lpmf(S[i] | lambda[i]);
  }
}
"
```


```{r}
m.1.2 <- stan(model_code=code_m1.2,data=dlist,chains=4,cores=4)
precis(m.1.2)
```


Adding research_effort did improve the sampling but not erase the association of brain size with social learning. That likely implies that research effort is a mediator.


## Posterior predictive checks

```{r}
set.seed(4)
post.1.2 <- extract.samples(m.1.2)
B_seq = seq(from=min(d2$logbrain), to=max(d2$logbrain), length.out=30)
R_seq = seq(from=min(d2$logresearch), to=max(d2$logresearch), length.out=30)

mu <- matrix(0,nrow=length(post.1.2$a),ncol=30)
for(i in 1:30){mu[,i] = exp(post.1.2$a + post.1.2$b1*B_seq[i] + post.1.2$b2*R_seq[i])}
mu.mean <- apply(mu,2,mean)
mu.pi <- apply(mu,2,PI,prob=0.89)
```

```{r}
sim.social1.2 <- matrix(0,nrow=length(post.1.2$a),ncol=30)
for(i in 1:30){sim.social1.2[,i] = rpois(1e3, lambda=exp(post.1.2$a + post.1.2$b1*B_seq[i] + post.1.2$b2*R_seq[i]))}
sim.pi <- apply(sim.social1.2, 2, PI, prob=0.89)
```


```{r}
plot(NULL, xlim=c(min(d2$logbrain),max(d2$logbrain)), ylim=c(min(d2$social_learning),max(d2$social_learning)),
     ylab="Social Learning", xlab="Log brain size")
points(x=d2$logbrain, y=d2$social_learning, col=rangi2)
lines(x=B_seq,y=mu.mean, col=col.alpha("black",1))
shade(mu.pi, B_seq, col=col.alpha("blue",0.5))
shade(sim.pi, B_seq, col=col.alpha("gray",0.5))
```


## DAGs

```{r}
dag1.1 <- dagitty("dag{
                  B->R->S
                  B->S
}")
coordinates(dag1.1) <- list(x=c(B=0,R=1,S=2),
                            y=c(B=0,R=-1,S=0))
drawdag(dag1.1)
```

# 2. Zero-inflated Poisson

## Initial statistical models

$$
S_{i} \sim ZIPoisson(p_{i},\lambda_{i})\\
logit(p_{i}) = \alpha_{p} + \beta_{b,p}B_{i} + \beta_{r,p}R_{i}\\
log(\lambda_{i}) = \alpha_{\lambda} + \beta_{b,\lambda}B_{i} + \beta_{r,\lambda}R_{i}\\
c(\alpha_{p},\alpha_{\lambda}) \sim Normal(0,1)\\
c(\beta_{b,p}, \beta_{r,p}, \beta_{b,\lambda}, \beta_{r,\lambda}) \sim Normal(0,0.5)
$$
```{r}
code_m2.1 <- "
data{
  int N;
  vector<lower=0>[N] B;
  vector<lower=0>[N] R;
  int S[N];
}
parameters{
  real ap;
  real al;
  real b11;
  real b12;
  real b21;
  real b22;
}
model{
  vector[N] p;
  vector[N] lambda;
  b11 ~ normal(0,0.5);
  b12 ~ normal(0,0.5);
  b21 ~ normal(0,0.5);
  b22 ~ normal(0,0.5);
  ap ~ normal(0,1);
  al ~ normal(0,1);
  for(i in 1:N){
    lambda[i] = al + b21*B[i] + b22*R[i];
    lambda[i] = exp(lambda[i]);
  }
  for(i in 1:N){
    p[i] = ap + b11*B[i] + b12*R[i];
    p[i] = inv_logit(p[i]);
  }
  for(i in 1:N){
    if (S[i]==0) target += log_mix(p[i],0,poisson_lpmf(0|lambda[i]));
    if (S[i]>0) target += log1m(p[i]) + poisson_lpmf(S[i]|lambda[i]);
  }
}
generated quantities{
  vector[N] log_lik;
  vector[N] lambda;
  vector[N] p;
  for(i in 1:N){
    lambda[i] = al + b21*B[i] + b22*R[i];
    lambda[i] = exp(lambda[i]);
  }
  for(i in 1:N){
    p[i] = ap + b11*B[i] + b12*R[i];
    p[i] = inv_logit(p[i]);
  }
  for(i in 1:N){
    if(S[i]==0) log_lik[i] = log_mix(p[i],0,poisson_lpmf(0|lambda[i]));
    if(S[i]>0) log_lik[i] = log1m(p[i]) + poisson_lpmf(S[i]|lambda[i]);
  }
}
"
```


```{r}
m.2.1 <- stan(model_code=code_m2.1,data=dlist,chains=4,cores=4)
precis(m.2.1)
```

## Posterior predictive checks

```{r}
set.seed(5)
post2.1 <- extract.samples(m.2.1)
B_seq = seq(from=min(d2$logbrain), to=max(d2$logbrain), length.out=30)
R_seq = seq(from=min(d2$logresearch), to=max(d2$logresearch), length.out=30)
mu <- matrix(0,nrow=length(post2.1$al),ncol=30)
for(i in 1:30){mu[,i] = exp(post2.1$al + post2.1$b21*B_seq[i] + post2.1$b22*R_seq[i])}
# mu <- link(m2.1, data=list(B=B_seq, R=R_seq))
mu.mean <- apply(mu,2,mean)
mu.pi <- apply(mu,2,PI,prob=0.89)
```

```{r}
sim.social <- matrix(0,nrow=length(post2.1$al),ncol=30)
for(i in 1:30){sim.social[,i] = rpois(1e3, lambda=exp(post2.1$al + post2.1$b21*B_seq[i] + post2.1$b22*R_seq[i]))}
# sim.social <- sim(m1.2, data = list(B=B_seq, R=R_seq))
sim.pi <- apply(sim.social, 2, PI, prob=0.89)
```


```{r}
plot(NULL, xlim=c(min(d2$logbrain),max(d2$logbrain)), ylim=c(min(d2$social_learning),max(d2$social_learning)),
     ylab="Social Learning", xlab="Log brain size")
points(x=d2$logbrain, y=d2$social_learning, col=rangi2)
lines(x=B_seq,y=mu.mean, col=col.alpha("black",1))
shade(mu.pi, B_seq, col=col.alpha("blue",0.5))
shade(sim.pi, B_seq, col=col.alpha("gray",0.5))
```

## Model comparison

```{r}
compare(m.1.1, m.1.2, m.2.1)
```
```{r}
compare(m.1.1, m.1.2, m.2.1, func = PSIS)
```

Both WAIC and PSIS agree on the outperformance of m2.1 in term of expected predictive accuracy. Note that the slight different between m1.2 and m2.1 is particular to the case study


# 3. Models with science knowledge

The models we are working with will consider the causal influence of group size on brain size by taking into the impact of phylogenetic distance and body mass

Theoretically, phylogenetic distance can have two important causal influences:
* Two species that only recently separated tend to be more similar
* Phylogentic distance is a proxy for unobserved variables that generate covariance among species

## DAGs

```{r}
dag3.1 <- dagitty("dag{
                  U[unobserved]
                  G->B
                  G<-M->B
                  G<-U->B
                  U->M
                  P->U
}")
coordinates(dag3.1) <- list(x=c(G=0,M=1,U=1,B=2,P=2),
                            y=c(G=0,M=1,U=2,B=0,P=2))
drawdag(dag3.1)
```

## Load data

```{r}
data("Primates301")
data("Primates301_nex")
```


```{r}
library(ape)
# plot(ladderize(Primates301_nex), type="fan", font=1, no.margin=TRUE,
#      label.offset=1, cex=0.5)
```

## An ordinary model in an un-ordinary style
$$
B \sim MVNormal(\mu, S)\\
\mu_{i}=\alpha + \beta_{G}G_{i} + \beta_{M}M_{i}\\
S=\sigma^{2}I
$$

```{r}
d <- Primates301
d$name <- as.character(d$name)
dstan <- d[complete.cases(d$group_size, d$boby, d$brain),]
spp_obs <- dstan$name
```


```{r}
dat_list <- list(
  N_spp = nrow(dstan),
  M = standardize(log(dstan$body)),
  B = standardize(log(dstan$brain)),
  G = standardize(log(dstan$group_size)),
  Imat = diag(nrow(dstan))
)
```

```{r}
code_m3.1 <- "
data{
  int N_spp;
  vector[N_spp] M;
  vector[N_spp] B;
  vector[N_spp] G;
  matrix[N_spp,N_spp] Imat;
}
parameters{
  real a;
  real bG;
  real bM;
  real<lower=0> sigma_sq;
}
model{
  vector[N_spp] mu;
  matrix[N_spp,N_spp] SIGMA;
  
  sigma_sq ~ exponential(1);
  bM ~ normal(0,0.5);
  bG ~ normal(0,0.5);
  a ~ normal(0,1);
  
  SIGMA = Imat*sigma_sq;
  for(i in 1:N_spp){
    mu[i] = a + bM*M[i] + bG*G[i];
  }
  B ~ multi_normal(mu, SIGMA);
}
generated quantities{
  vector[N_spp] mu;
  vector[N_spp] log_lik;
  matrix[N_spp,N_spp] SIGMA;
  
  SIGMA = Imat*sigma_sq;
  for(i in 1:N_spp){
    mu[i] = a + bM*M[i] + bG*G[i];
  }
  for(i in 1:N_spp){
    log_lik[i] = multi_normal_lpdf(B | mu, SIGMA);
  }
}
"
```


```{r}
m.3.1 <- stan(model_code=code_m3.1,data=dat_list,chains=4,cores=4)
precis(m.3.1)
```

## Brownian motion model

The Brownian motion means Gaussian random walks. If species traits drift randomly with respect to one another after speciation, then the covariance between a pair of species ends up being linearly related to the phylogenetic branch distance between them.

```{r}
tree_trimmed <- keep.tip( Primates301_nex, spp_obs )
Rbm <- corBrownian( phy=tree_trimmed )
V <- vcv(Rbm)
Dmat <- cophenetic( tree_trimmed )
plot( Dmat, V , xlab="phylogenetic distance" , ylab="covariance" )
```


```{r}
dat_list$V <- V[spp_obs, spp_obs]
dat_list$R <- dat_list$V/max(V)
```

We'll replace the covariance matrix S with a matrix R that encodes phylogenetic information

```{r}
code_m3.2 <- "
data{
  int N_spp;
  vector[N_spp] M;
  vector[N_spp] B;
  vector[N_spp] G;
  matrix[N_spp,N_spp] R;
}
parameters{
  real a;
  real bG;
  real bM;
  real<lower=0> sigma_sq;
}
model{
  vector[N_spp] mu;
  matrix[N_spp,N_spp] SIGMA;
  
  sigma_sq ~ exponential(1);
  bM ~ normal(0,0.5);
  bG ~ normal(0,0.5);
  a ~ normal(0,1);
  
  SIGMA = R*sigma_sq;
  
  for(i in 1:N_spp){
    mu[i] = a + bM*M[i] + bG*G[i];
  }
  B ~ multi_normal(mu, SIGMA);
}
generated quantities{
  vector[N_spp] mu;
  vector[N_spp] log_lik;
  matrix[N_spp,N_spp] SIGMA;
  
  SIGMA = R*sigma_sq;
  
  for(i in 1:N_spp){
    mu[i] = a + bM*M[i] + bG*G[i];
  }
  for(i in 1:N_spp){
    log_lik[i] = multi_normal_lpdf(B | mu, SIGMA);
  }
}
"
```


```{r}
m.3.2 <- stan(model_code=code_m3.2,data=dat_list,chains=4,cores=4)
precis(m.3.2)
```

The estimate for bG implies of disappeared association between group size and brain size.

In the model below, we'll replace the Brownian motion with OU process which constrain the variation and make the relationship between phylogenetic distance and covariance non-linear as the formula

$$
K(i,j) = \eta^{2}exp(-\rho^{2}D_{ij})
$$

```{r}
dat_list$Dmat <- Dmat[spp_obs, spp_obs]/max(Dmat)
```

```{r}
code_m3.3 <- "
functions{
  matrix cov_GPL1(matrix x, real sq_alpha, real sq_rho, real delta){
    int N = dims(x)[1];
    matrix[N,N] K;
    for(i in 1:N-1){
      K[i,i] = sq_alpha + delta;
      for(j in (i+1):N){
        K[i,j] = sq_alpha * exp(-sq_rho * x[i,j]);
        K[j,i] = K[i,j];
      }
    }
    K[N,N] = sq_alpha + delta;
    return K;
  }
}
data{
  int N_spp;
  vector[N_spp] M;
  vector[N_spp] B;
  vector[N_spp] G;
  matrix[N_spp,N_spp] Dmat;
}
parameters{
  real a;
  real bG;
  real bM;
  real<lower=0> etasq;
  real<lower=0> rhosq;
}
model{
  vector[N_spp] mu;
  matrix[N_spp,N_spp] SIGMA;
  rhosq ~ normal(3,0.25);
  etasq ~ normal(1,0.25);
  bM ~ normal(0,0.5);
  bG ~ normal(0,0.5);
  a ~ normal(0,1);
  
  SIGMA = cov_GPL1(Dmat, etasq, rhosq, 0.01);
  
  for(i in 1:N_spp){
    mu[i] = a + bM*M[i] + bG*G[i];
  }
  B ~ multi_normal(mu, SIGMA);
}
generated quantities{
  vector[N_spp] mu;
  vector[N_spp] log_lik;
  matrix[N_spp,N_spp] SIGMA;
  
  SIGMA = cov_GPL1(Dmat, etasq, rhosq, 0.01);
  
  for(i in 1:N_spp){
    mu[i] = a + bM*M[i] + bG*G[i];
  }
  for(i in 1:N_spp){
    log_lik[i] = multi_normal_lpdf(B | mu, SIGMA);
  }
}
"
```


```{r}
m.3.3 <- stan(model_code=code_m3.3,data=dat_list,chains=4,cores=4)
precis(m.3.3)
```


```{r}
post <- extract.samples(m.3.3)
plot(NULL, xlim=c(0,max(dat_list$Dmat)), ylim=c(0,1.5),
     xlab="phylogenetic distance", ylab="covariance")

for(i in 1:30){
  curve(post$etasq[i]*exp(-post$rhosq[i]*x), add=TRUE, col=rangi2)
}

eta <- abs(rnorm(n=1e3,mean=1,sd=0.25))
rho <- abs(rnorm(n=1e3,mean=3,sd=0.25))
d_seq <- seq(from=0,to=1,length.out=50)
K <- sapply(d_seq, function(x){eta*exp(-rho*x)})

lines(d_seq, colMeans(K), lwd=2)
shade(apply(K,2,PI),d_seq)
text(0.5,0.5,"prior")
text(0.2,0.1,"posterior",col=rangi2)
```

# 4. Models with measurement errors

We'll make up some unknown errors that are supposed to be proportional to the measurement of brain volume and body mass.

```{r}
data(Primates301)
d <- Primates301
cc <- complete.cases( d$brain , d$body )
B <- d$brain[cc]
M <- d$body[cc]
B <- B / max(B)
M <- M / max(M)
```

That proportion makes the uncertainty not uniform across the values. Here, error is 10% of the measurement.

```{r}
Bse <- B*0.1
Mse <- M*0.1
```

## Fit a model without considering the errors

```{r}
dat_list <- list(B=B, M=M, N=length(B))
```

```{r}
code_m4.1 <- "
data{
  int N;
  vector[N] B;
  vector[N] M;
}
parameters{
  real a;
  real b;
  real<lower=0> sigma;
}
model{
  vector[N] mu;
  sigma ~ exponential(1);
  a ~ normal(0,1);
  b ~ normal(0,1);
  for(i in 1:N){
    mu[i] = a + b*log(M[i]);
  }
  B ~ lognormal(mu, sigma);
}
generated quantities{
  vector[N] log_lik;
  vector[N] mu;
  for(i in 1:N){
    mu[i] = a + b*log(M[i]);
  }
  for(i in 1:N){
    log_lik[i] = normal_lpdf(B[i] | mu[i], sigma);
  }
}
"
```


```{r}
m.4.1 <- stan(model_code=code_m4.1,data=dat_list,chains=4,cores=4)
precis(m.4.1)
```

```{r}
post4.1 <- extract.samples(m.4.1)
M_seq = seq(from=min(dat_list$M), to=max(dat_list$M), length.out=30)
med <- matrix(0,nrow=length(post4.1$a),ncol=30)
for(i in 1:30){med[,i] = exp(post4.1$a + post4.1$b*log(M_seq[i]))}
# med = exp(link(m4.1, data=list(M=M_seq)))
med.mean = apply(med,2,mean)
med.pi = apply(med,2,PI,prob=0.89)
```

```{r}
plot(NULL,xlim=c(min(dat_list$M),max(dat_list$M)),
     ylim=c(min(dat_list$B),max(dat_list$B)),
     xlab="Body mass", ylab="Brain size")
points(x=dat_list$M, y=dat_list$B, col=col.alpha(rangi2,0.5))
lines(x=M_seq, med.mean)
shade(med.pi,M_seq)
```

## Fit a model including the errors

```{r}
dlist <- list(B_obs=B, M_obs=M, N=length(B), B_se=Bse, M_se=Mse)
```

```{r}
code_m4.2 <- "
data{
  int N;
  vector[N] B_obs;
  vector[N] M_obs;
  vector[N] B_se;
  vector[N] M_se;
}
parameters{
  real<lower=0> sigma;
  real a;
  real b;
  vector<lower=0>[N] M_true;
  vector<lower=0>[N] B_true;
}
model{
  vector[N] mu;

  sigma ~ exponential(1);
  a ~ normal(0,1);
  b ~ normal(0,1);
  M_true ~ lognormal(0,1);
  M_obs ~ normal(M_true, M_se);
  for(i in 1:N){
    mu[i] = a + b*log(M_true[i]);
  }
  B_true ~ lognormal(mu, sigma);
  B_obs ~ normal(B_true, B_se);
}
generated quantities{
  vector[N] log_lik;
  vector[N] mu;
  for(i in 1:N){
    mu[i] = a + b*log(M_true[i]);
  }
  for(i in 1:N){
    log_lik[i] = normal_lpdf(B_obs[i] | B_true, B_se[i]);
  }
}
"
```


```{r}
m.4.2 <- stan(model_code=code_m4.2,data=dlist,chains=4,cores=4)
precis(m.4.2)
```

```{r}
set.seed(11)
post4.2 <- extract.samples(m.4.2)

M_seq = seq(from=min(dlist$M_obs), to=max(dlist$M_obs), length.out=50)
B.med <- matrix(0,nrow=length(post4.2$a), ncol=50)
for(i in 1:50){B.med[,i] = exp(post4.2$a + post4.2$b*log(M_seq[i]))}
B.med_mean <- apply(B.med,2,mean)
B.med_pi <- apply(B.med,2,PI,prob=0.89)

B_true <- apply(post4.2$B_true,2,mean)
M_true <- apply(post4.2$M_true,2,mean)
plot(dlist$M_obs, dlist$B_obs, pch=1, col=rangi2,xlab="Body mass", ylab="Brain size")
# points(x=M_true, y=B_true)

lines(x=M_seq, y=B.med_mean)
shade(B.med_pi,M_seq)
```


```{r}
compare(m.4.2, m.4.1, func=PSIS)
```

```{r}
compare(m.4.2, m.4.1, func=WAIC)
```

Three things should be highlighted:

* m4.1 faces obstacles to deal with the data points with high brain size and high body mass. Meanwhile, accounting for measurement errors allows m4.2 to justify them.
* m4.2 receives warnings of unreliable sampling that does not happen to m4.1
* PSIS and WAIC agree on that m4.1 has a better expected predictive accuracy than m4.2

```{r}
```

